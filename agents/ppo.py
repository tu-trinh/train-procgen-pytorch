from .base_agent import BaseAgent
from common.misc_util import adjust_lr, get_n_params
from common.constants import *
import torch
import torch.optim as optim
import numpy as np
import pickle


class PPO(BaseAgent):
    def __init__(self,
                 env,
                 policy,
                 logger,
                 storage,
                 device,
                 n_checkpoints,
                 save_timesteps=None,
                 reduced_action_space=False,
                 store_percentiles=False,
                 all_sampled_probs=[],
                 all_max_probs=[],
                 all_sampled_logits=[],
                 all_max_logits=[],
                 all_entropies=[],
                 probs_by_action={},
                 logits_by_action={},
                 entropies_by_action={},
                 all_help_info=[],
                 env_valid=None,
                 storage_valid=None,
                 n_steps=128,
                 n_envs=8,
                 epoch=3,
                 mini_batch_per_epoch=8,
                 mini_batch_size=32*8,
                 gamma=0.99,
                 lmbda=0.95,
                 learning_rate=2.5e-4,
                 grad_clip_norm=0.5,
                 eps_clip=0.2,
                 value_coef=0.5,
                 entropy_coef=0.01,
                 normalize_adv=True,
                 normalize_rew=True,
                 use_gae=True,
                 **kwargs):

        super(PPO, self).__init__(env, policy, logger, storage, device,
                                  n_checkpoints, save_timesteps, env_valid, storage_valid)

        self.n_steps = n_steps
        self.n_envs = n_envs
        self.reduced_action_space = reduced_action_space
        self.store_percentiles = store_percentiles
        self.epoch = epoch
        self.mini_batch_per_epoch = mini_batch_per_epoch
        self.mini_batch_size = mini_batch_size
        self.gamma = gamma
        self.lmbda = lmbda
        self.learning_rate = learning_rate
        self.optimizer = optim.Adam(self.policy.parameters(), lr=learning_rate, eps=1e-5)
        self.grad_clip_norm = grad_clip_norm
        self.eps_clip = eps_clip
        self.value_coef = value_coef
        self.entropy_coef = entropy_coef
        self.normalize_adv = normalize_adv
        self.normalize_rew = normalize_rew
        self.use_gae = use_gae

        if self.store_percentiles:
            self.all_max_probs = all_max_probs
            self.all_sampled_probs = all_sampled_probs
            self.all_max_logits = all_max_logits
            self.all_sampled_logits = all_sampled_logits
            self.all_entropies = all_entropies
            self.probs_by_action = probs_by_action
            self.logits_by_action = logits_by_action
            self.entropies_by_action = entropies_by_action

        self.request_limit = 3
        self.num_requests = 0
        self.num_actions = env.action_space.n
        if self.reduced_action_space:
            self.probability_thresholds = 0.010620193323120477
            self.logit_thresholds = -4.544998216629028
            self.entropy_thresholds = 2.1931112485913173
        else:
            # FIXME: get 1: percentile?
            self.max_probability_thresholds = {5: 0.09819576181471348, 10: 0.10543024390935898, 15: 0.11278309598565102, 20: 0.12015544027090073, 25: 0.12764990329742432, 30: 0.13590438216924666, 35: 0.14417276531457898, 40: 0.15355215668678285, 45: 0.16340279579162598, 50: 0.17365284264087677, 55: 0.1861933097243309, 60: 0.2008519649505615, 65: 0.21826076358556748, 70: 0.24089968055486677, 75: 0.2715589925646782, 80: 0.317707359790802, 85: 0.3875697061419486, 90: 0.5035062968730929, 95: 0.7015094965696334, 99: 0.9638708305358886}
            self.sampled_probability_thresholds = {5: 0.03283343184739351, 10: 0.043655799329280855, 15: 0.05117972083389759, 20: 0.057213302701711655, 25: 0.062359703704714775, 30: 0.06723010390996934, 35: 0.07225508242845534, 40: 0.07756723165512085, 45: 0.08325664885342121, 50: 0.08955096453428268, 55: 0.09714770950376989, 60: 0.10667413175106048, 65: 0.11979856416583064, 70: 0.13728418201208112, 75: 0.16238053143024445, 80: 0.19856784939765934, 85: 0.26137103140354156, 90: 0.386662930250168, 95: 0.6480066418647763, 99: 0.963208303451538}
            self.max_logit_thresholds = {5: -2.3207921624183654, 10: -2.2497056245803835, 15: -2.1822886943817137, 20: -2.1189690113067625, 25: -2.058463752269745, 30: -1.9958036541938782, 35: -1.93674293756485, 40: -1.8737149000167848, 45: -1.8115370273590088, 50: -1.750697135925293, 55: -1.680969876050949, 60: -1.605187225341797, 65: -1.5220647931098938, 70: -1.42337464094162, 75: -1.303575873374939, 80: -1.1466246843338013, 85: -0.9478595763444904, 90: -0.6861590564250942, 95: -0.3545207634568216, 99: -0.03679789271205672}
            self.sampled_logit_thresholds = {5: -3.416308045387268, 10: -3.1314191818237305, 15: -2.97241188287735, 20: -2.860968732833862, 25: -2.7748358845710754, 30: -2.6996340274810793, 35: -2.627552592754364, 40: -2.556610345840454, 45: -2.4858272433280946, 50: -2.412947416305542, 55: -2.3315226435661316, 60: -2.2379767417907717, 65: -2.1219435691833493, 70: -1.98570214509964, 75: -1.8178127706050873, 80: -1.61662437915802, 85: -1.341814249753952, 90: -0.9502019226551052, 95: -0.43385428637266216, 99: -0.03748557247221489}
            self.entropy_thresholds = {5: 0.7102466046810151, 10: 1.5199036359786988, 15: 1.8848632752895356, 20: 2.067613363265991, 25: 2.1740341782569885, 30: 2.2490103006362916, 35: 2.3087543845176697, 40: 2.353701877593994, 45: 2.3999591588974, 50: 2.4426052570343018, 55: 2.485910999774933, 60: 2.524513339996338, 65: 2.559413433074951, 70: 2.5892781972885133, 75: 2.6125972867012024, 80: 2.630497455596924, 85: 2.6447925567626953, 90: 2.6571274757385255, 95: 2.6699509620666504, 99: 2.6845493054389955}
            self.probability_thresholds_by_action = {0: {5: 0.016009352635592222, 10: 0.027217776514589787, 15: 0.03813684359192848, 20: 0.04672176018357277, 25: 0.053883145563304424, 30: 0.06154246628284454, 35: 0.06855160370469093, 40: 0.07476421445608139, 45: 0.08052914962172508, 50: 0.08689902722835541, 55: 0.0929117314517498, 60: 0.10035613179206848, 65: 0.11027081310749054, 70: 0.1260787770152092, 75: 0.15334198623895645, 80: 0.2049793303012848, 85: 0.29145195335149765, 90: 0.38175857067108154, 95: 0.4738757982850075, 99: 0.6722038507461547}, 1: {5: 0.020540709234774114, 10: 0.03454271256923676, 15: 0.05028628222644326, 20: 0.061659663915634155, 25: 0.07074147462844849, 30: 0.07781312018632887, 35: 0.08400990888476371, 40: 0.0892286792397499, 45: 0.09477358832955361, 50: 0.1004280373454094, 55: 0.10614676102995872, 60: 0.11266751885414124, 65: 0.1197207897901535, 70: 0.12892524898052216, 75: 0.14200382679700851, 80: 0.1664457470178604, 85: 0.22733610570430746, 90: 0.3037332475185397, 95: 0.41617739796638487, 99: 0.5570968413352967}, 2: {5: 0.016696565225720408, 10: 0.028755253925919533, 15: 0.039759501628577706, 20: 0.05060239210724831, 25: 0.05994328763335943, 30: 0.06705995500087737, 35: 0.0738337218761444, 40: 0.0796144112944603, 45: 0.08515311554074287, 50: 0.09125861525535583, 55: 0.0987539865076542, 60: 0.10700687617063522, 65: 0.11662983149290088, 70: 0.12952934354543683, 75: 0.14342105761170387, 80: 0.16145063936710358, 85: 0.19538904577493663, 90: 0.3043039858341217, 95: 0.6049809306859957, 99: 0.943596843481064}, 3: {5: 0.03433978408575058, 10: 0.043009071797132495, 15: 0.0479723822325468, 20: 0.052617197483778, 25: 0.05631022434681654, 30: 0.059952855482697485, 35: 0.06334334947168827, 40: 0.06670954227447509, 45: 0.07069271467626095, 50: 0.07510942220687866, 55: 0.07989569306373596, 60: 0.08522644340991974, 65: 0.09105964824557304, 70: 0.09824314415454863, 75: 0.10819144733250141, 80: 0.12181878387928012, 85: 0.1400007918477058, 90: 0.16883472651243212, 95: 0.22816869542002677, 99: 0.370605033636093}, 4: {5: 0.03134456090629101, 10: 0.039034544676542285, 15: 0.04418265372514724, 20: 0.0483169972896576, 25: 0.0519376564770937, 30: 0.05485753118991852, 35: 0.057707072049379346, 40: 0.06054303646087647, 45: 0.06324417889118195, 50: 0.06592166423797607, 55: 0.06851380094885827, 60: 0.07103603482246398, 65: 0.07413907572627068, 70: 0.0775960549712181, 75: 0.08218052238225937, 80: 0.08966970145702365, 85: 0.100537983328104, 90: 0.1194140836596489, 95: 0.15323526710271831, 99: 0.24201873064041132}, 5: {5: 0.029990973323583605, 10: 0.04027651995420456, 15: 0.04692990705370903, 20: 0.052376812696456915, 25: 0.057427600026130676, 30: 0.06140338107943535, 35: 0.06537243574857711, 40: 0.06970508694648746, 45: 0.0742297500371933, 50: 0.07898137718439102, 55: 0.0847818434238434, 60: 0.0904368236660957, 65: 0.09881253242492676, 70: 0.11114215850830078, 75: 0.12475064396858215, 80: 0.14231287837028506, 85: 0.1650857895612716, 90: 0.20052199065685275, 95: 0.28035708069801296, 99: 0.48898856997489815}, 6: {5: 0.06114049255847931, 10: 0.07347460091114044, 15: 0.08631004765629768, 20: 0.09973599016666412, 25: 0.11200973205268383, 30: 0.12598934769630432, 35: 0.14042657613754272, 40: 0.15591534972190857, 45: 0.17317365854978561, 50: 0.19331835210323334, 55: 0.21754630655050283, 60: 0.25085440278053284, 65: 0.3009180575609207, 70: 0.37169095873832675, 75: 0.45773374289274216, 80: 0.5672661662101746, 85: 0.6891191005706787, 90: 0.814071774482727, 95: 0.9210814982652664, 99: 0.9798298120498657}, 7: {5: 0.04215540010482073, 10: 0.05667116940021515, 15: 0.07087359726428985, 20: 0.08683086931705475, 25: 0.10085077583789825, 30: 0.11679613143205642, 35: 0.13223717063665388, 40: 0.14776351451873784, 45: 0.16455591022968294, 50: 0.18065430223941803, 55: 0.20099076405167585, 60: 0.22281184494495387, 65: 0.24952041581273082, 70: 0.28065908253192884, 75: 0.32766494899988174, 80: 0.39094605445861824, 85: 0.47421279102563857, 90: 0.5922852993011475, 95: 0.7539778620004653, 99: 0.9414309418201443}, 8: {5: 0.026922013983130457, 10: 0.03435271605849266, 15: 0.043600152432918544, 20: 0.05621017515659334, 25: 0.0718945749104023, 30: 0.08977590352296828, 35: 0.10724633708596228, 40: 0.12663123309612276, 45: 0.14808651804924017, 50: 0.17355768382549286, 55: 0.20289591252803807, 60: 0.24039582014083857, 65: 0.298385363817215, 70: 0.3633541405200958, 75: 0.46285052597522736, 80: 0.5871395587921142, 85: 0.7613085031509398, 90: 0.9419011354446427, 95: 0.997381067276001, 99: 1.0}, 9: {5: 0.027882118709385395, 10: 0.03413084782660008, 15: 0.03819945640861988, 20: 0.0414673775434494, 25: 0.04411579668521881, 30: 0.04680775851011276, 35: 0.04915941189974546, 40: 0.05158983916044235, 45: 0.054172854870557785, 50: 0.05637181177735329, 55: 0.059033102728426455, 60: 0.0617764838039875, 65: 0.0648668110370636, 70: 0.06876485049724577, 75: 0.07370059937238693, 80: 0.08096678256988529, 85: 0.0912612996995449, 90: 0.1087896838784218, 95: 0.13975176364183423, 99: 0.22433039546012878}, 10: {5: 0.0324534572660923, 10: 0.043355145305395124, 15: 0.0494890384376049, 20: 0.054077810049057005, 25: 0.057478178292512894, 30: 0.060504887253046036, 35: 0.06321947127580643, 40: 0.06597603261470796, 45: 0.06866113692522048, 50: 0.07154618203639984, 55: 0.07441297918558121, 60: 0.07743041366338729, 65: 0.08066118061542511, 70: 0.08398192375898361, 75: 0.08851674199104309, 80: 0.09419769495725631, 85: 0.10224618762731552, 90: 0.11421801149845123, 95: 0.13625003695487975, 99: 0.21521690964698773}, 11: {5: 0.03518996573984623, 10: 0.043547019734978674, 15: 0.04928395636379719, 20: 0.053768813610076904, 25: 0.057755857706069946, 30: 0.06171320416033268, 35: 0.06522578559815884, 40: 0.06841891556978226, 45: 0.07232926972210407, 50: 0.07569225132465363, 55: 0.0792071782052517, 60: 0.08300425559282303, 65: 0.08723609708249569, 70: 0.091546730697155, 75: 0.09744766168296337, 80: 0.10453050583600998, 85: 0.11626534909009933, 90: 0.1332768201828003, 95: 0.16738824397325508, 99: 0.25356215238571167}, 12: {5: 0.035761328786611556, 10: 0.04675749391317368, 15: 0.053590711951255796, 20: 0.05834287106990814, 25: 0.061962734907865524, 30: 0.06539038121700287, 35: 0.0685320496559143, 40: 0.07184291332960129, 45: 0.07518178820610047, 50: 0.07881384342908859, 55: 0.08263244628906251, 60: 0.08669904619455338, 65: 0.09065614789724352, 70: 0.09520164430141449, 75: 0.09988929331302643, 80: 0.10536900013685227, 85: 0.11246422529220582, 90: 0.12284998744726182, 95: 0.14054092466831175, 99: 0.20472238481044777}, 13: {5: 0.03780358359217644, 10: 0.04833291694521904, 15: 0.05557046830654144, 20: 0.06086359918117524, 25: 0.06457573920488358, 30: 0.06799974590539933, 35: 0.07059275656938553, 40: 0.07353544533252716, 45: 0.07601579874753953, 50: 0.0787758082151413, 55: 0.08124217987060547, 60: 0.08380448222160339, 65: 0.08640269190073015, 70: 0.08925644308328627, 75: 0.09281743317842484, 80: 0.09704968631267548, 85: 0.10314199477434158, 90: 0.11281585544347768, 95: 0.14285507202148437, 99: 0.24142126202583342}, 14: {5: 0.036000704020261766, 10: 0.04448193535208702, 15: 0.04992755874991417, 20: 0.05486384108662606, 25: 0.05850086733698845, 30: 0.061797965317964554, 35: 0.06495387107133865, 40: 0.06824024021625519, 45: 0.07213115692138672, 50: 0.07563911378383636, 55: 0.07967326045036317, 60: 0.08418064564466476, 65: 0.08879137933254243, 70: 0.09463594257831573, 75: 0.10201037675142288, 80: 0.1100757047533989, 85: 0.12113018333911894, 90: 0.13828255832195283, 95: 0.16277646720409392, 99: 0.26175405263900736}}
            self.logit_thresholds_by_action = {0: {5: -4.134582757949829, 10: -3.603885054588318, 15: -3.266574501991272, 20: -3.0635452270507812, 25: -2.9209375977516174, 30: -2.7880278825759888, 35: -2.680168569087982, 40: -2.5934157371520996, 45: -2.519136071205139, 50: -2.4430084228515625, 55: -2.37610524892807, 60: -2.299030303955078, 65: -2.2048161029815674, 70: -2.0708484649658203, 75: -1.8750846683979034, 80: -1.5848459005355835, 85: -1.232880175113678, 90: -0.9629673659801483, 95: -0.746810108423233, 99: -0.3971936628222466}, 1: {5: -3.885361099243164, 10: -3.3655588150024416, 15: -2.9900240182876594, 20: -2.7861251831054688, 25: -2.6487233638763428, 30: -2.553445386886597, 35: -2.47682044506073, 40: -2.416552782058716, 45: -2.3562644243240354, 50: -2.298313856124878, 55: -2.242932677268982, 60: -2.1833141326904295, 65: -2.1225929975509645, 70: -2.04852237701416, 75: -1.9519011974334717, 80: -1.7930858612060547, 85: -1.4813256502151493, 90: -1.1916057825088493, 95: -0.8766437113285065, 99: -0.5850160467624664}, 2: {5: -4.092552876472473, 10: -3.5489349365234375, 15: -3.2249064207077027, 20: -2.9837564945220945, 25: -2.8143563866615295, 30: -2.702168011665344, 35: -2.6059397935867312, 40: -2.5305601596832275, 45: -2.4633042335510256, 50: -2.394057869911194, 55: -2.315123498439789, 60: -2.2348620891571045, 65: -2.1487502694129943, 70: -2.0438478708267214, 75: -1.941970705986023, 80: -1.8235558748245237, 85: -1.6327627897262575, 90: -1.1897281408309934, 95: -0.5025604307651541, 99: -0.058056620247661894}, 3: {5: -3.3714508175849915, 10: -3.1463441848754883, 15: -3.037129831314087, 20: -2.944712257385254, 25: -2.8768792152404785, 30: -2.81419677734375, 35: -2.7591853499412538, 40: -2.707407283782959, 45: -2.6494128346443175, 50: -2.5888092517852783, 55: -2.5270333647727967, 60: -2.462443542480469, 65: -2.3962405800819395, 70: -2.3203097343444825, 75: -2.2238531708717346, 80: -2.1052207946777344, 85: -1.9661072671413424, 90: -1.7788349390029905, 95: -1.4776700735092163, 99: -0.9926190167665485}, 4: {5: -3.4627145290374757, 10: -3.243308353424072, 15: -3.1194229602813723, 20: -3.029971885681152, 25: -2.9577112197875977, 30: -2.9030158042907717, 35: -2.852375626564026, 40: -2.804400825500488, 45: -2.7607522726058957, 50: -2.7192881107330322, 55: -2.6807200431823732, 60: -2.6445679664611816, 65: -2.6018125772476197, 70: -2.556238794326782, 75: -2.498837113380432, 80: -2.411622381210327, 85: -2.297219705581665, 90: -2.12515811920166, 95: -1.8757808804512026, 99: -1.4187403798103335}, 5: {5: -3.5068588256835938, 10: -3.2119866847991942, 15: -3.0591002464294434, 20: -2.9492913246154786, 25: -2.8572301864624023, 30: -2.790290355682373, 35: -2.7276546001434325, 40: -2.6634821414947507, 45: -2.6005902767181395, 50: -2.538543224334717, 55: -2.467673873901367, 60: -2.4031038284301762, 65: -2.314530944824219, 70: -2.1969451904296875, 75: -2.0814383029937744, 80: -1.9497272968292236, 85: -1.8012901782989506, 90: -1.606831359863281, 95: -1.271691417694093, 99: -0.715432863235476}, 6: {5: -2.7945809364318848, 10: -2.6108155250549316, 15: -2.4498093128204346, 20: -2.3052287101745605, 25: -2.1891695857048035, 30: -2.0715579986572266, 35: -1.9630705118179321, 40: -1.8584421873092651, 45: -1.7534604370594025, 50: -1.6434168815612793, 55: -1.5253435373306272, 60: -1.3828825950622559, 65: -1.2009173333644867, 70: -0.9896925985813149, 75: -0.7814675867557526, 80: -0.5669267177581787, 85: -0.37234118580818176, 90: -0.20570676773786545, 95: -0.08220677450299263, 99: -0.02037641936913127}, 7: {5: -3.16639221906662, 10: -2.870489740371704, 15: -2.6468573689460753, 20: -2.4437930583953857, 25: -2.294113278388977, 30: -2.1473253250122073, 35: -2.023158037662506, 40: -1.9121421337127682, 45: -1.8045049548149108, 50: -1.7111701369285583, 55: -1.6044963479042051, 60: -1.5014276027679445, 65: -1.3882145583629608, 70: -1.270614635944367, 75: -1.1157636940479279, 80: -0.9391856551170348, 85: -0.746099066734314, 90: -0.5237668693065642, 95: -0.28239228427410135, 99: -0.06035426814109129}, 8: {5: -3.6148110151290895, 10: -3.3710741996765137, 15: -3.132694721221924, 20: -2.8786580562591553, 25: -2.632554531097412, 30: -2.410438632965088, 35: -2.2326269149780273, 40: -2.0664760589599607, 45: -1.9099586367607113, 50: -1.7512452602386475, 55: -1.5950621604919433, 60: -1.4254686355590822, 65: -1.2093695402145384, 70: -1.0123772621154785, 75: -0.7703511714935303, 80: -0.532492744922638, 85: -0.27271676361560837, 90: -0.05985495895147156, 95: -0.0026221318636089567, 99: 0.0}, 9: {5: -3.579769730567932, 10: -3.3775537252426147, 15: -3.264934039115906, 20: -3.182848262786865, 25: -3.1209373474121094, 30: -3.061706280708313, 35: -3.012686920166016, 40: -2.964430570602417, 45: -2.9155752301216125, 50: -2.875786066055298, 55: -2.829657053947449, 60: -2.784232425689697, 65: -2.7354191899299622, 70: -2.6770626068115235, 75: -2.607744336128235, 80: -2.513716316223144, 85: -2.3940284490585326, 90: -2.2183387041091915, 95: -1.9678875505924227, 99: -1.4946353435516357}, 10: {5: -3.4279481887817385, 10: -3.1383299827575684, 15: -3.006004047393799, 20: -2.91733136177063, 25: -2.8563499450683594, 30: -2.805031156539917, 35: -2.7611430168151854, 40: -2.7184638023376464, 45: -2.678572082519531, 50: -2.6374120712280273, 55: -2.59812479019165, 60: -2.5583755493164064, 65: -2.5174981117248536, 70: -2.477153778076172, 75: -2.424563407897949, 80: -2.3623595237731934, 85: -2.28037166595459, 90: -2.1696462631225586, 95: -1.993263578414917, 99: -1.5361097526550302}, 11: {5: -3.346994471549988, 10: -3.133914017677307, 15: -3.0101567268371583, 20: -2.92306170463562, 25: -2.851530432701111, 30: -2.785257363319397, 35: -2.7299005508422853, 40: -2.682105875015259, 45: -2.626526391506195, 50: -2.5810794830322266, 55: -2.5356883883476256, 60: -2.4888635158538817, 65: -2.439137101173401, 70: -2.3909056425094604, 75: -2.3284398317337036, 80: -2.2582763195037843, 85: -2.1518800258636475, 90: -2.015326976776123, 95: -1.7874394297599796, 99: -1.3721463680267334}, 12: {5: -3.3308887481689453, 10: -3.062780809402466, 15: -2.9263796329498293, 20: -2.8414181232452393, 25: -2.781222105026245, 30: -2.7273802280426027, 35: -2.6804537773132324, 40: -2.6332733154296877, 45: -2.587846374511719, 50: -2.5406665802001953, 55: -2.493352699279785, 60: -2.4453125, 65: -2.4006815433502195, 70: -2.3517580032348633, 75: -2.3036928176879883, 80: -2.250286865234375, 85: -2.1851200580596926, 90: -2.0967912673950195, 95: -1.9622567892074607, 99: -1.5861005353927609}, 13: {5: -3.2753517150878904, 10: -3.0296424865722655, 15: -2.890103340148926, 20: -2.799120044708252, 25: -2.7399168014526367, 30: -2.6882513999938964, 35: -2.650827693939209, 40: -2.609987735748291, 45: -2.576814126968384, 50: -2.541149377822876, 55: -2.510320806503296, 60: -2.479268789291382, 65: -2.448736476898193, 70: -2.4162416934967044, 75: -2.3771207332611084, 80: -2.3325321674346924, 85: -2.2716487407684327, 90: -2.1819985389709466, 95: -1.9459246397018433, 99: -1.4212123632431017}, 14: {5: -3.3242167472839355, 10: -3.1126720905303955, 15: -2.997182083129883, 20: -2.9029008865356443, 25: -2.8387136459350586, 30: -2.783884811401367, 35: -2.7340779304504395, 40: -2.6847208976745605, 45: -2.6292692184448243, 50: -2.5817816257476807, 55: -2.5298213958740234, 60: -2.4747901916503907, 65: -2.421465539932251, 70: -2.357717990875244, 75: -2.2826807498931885, 80: -2.206587076187134, 85: -2.110889434814453, 90: -1.97845618724823, 95: -1.8153773546218872, 99: -1.3403502798080453}}
            self.entropy_thresholds_by_action = {0: {5: 1.3445005118846893, 10: 1.6914395093917847, 15: 1.9637117087841034, 20: 2.151820182800293, 25: 2.2688559889793396, 30: 2.3500571250915527, 35: 2.4096816182136536, 40: 2.463852882385254, 45: 2.5183090567588806, 50: 2.557812452316284, 55: 2.584205389022827, 60: 2.6039578914642334, 65: 2.6179950833320618, 70: 2.629602551460266, 75: 2.639212429523468, 80: 2.64854097366333, 85: 2.656724691390991, 90: 2.6648460626602173, 95: 2.674552083015442, 99: 2.6857173442840576}, 1: {5: 1.4152308344841003, 10: 1.8218470811843872, 15: 2.0829181909561156, 20: 2.2450721740722654, 25: 2.3533440828323364, 30: 2.4253538131713865, 35: 2.4851428508758544, 40: 2.5299845218658445, 45: 2.5629979848861697, 50: 2.586264133453369, 55: 2.60212984085083, 60: 2.6163280487060545, 65: 2.6271376609802246, 70: 2.636640739440918, 75: 2.6455297470092773, 80: 2.6526278018951417, 85: 2.6597781419754027, 90: 2.667592096328735, 95: 2.6770828485488893, 99: 2.68591103553772}, 2: {5: 1.2336591541767121, 10: 1.8835667610168458, 15: 2.217313528060913, 20: 2.3763607025146487, 25: 2.4652830958366394, 30: 2.5141324758529664, 35: 2.5550779700279236, 40: 2.5787937164306642, 45: 2.5948526263237, 50: 2.6085530519485474, 55: 2.6202569127082826, 60: 2.6305595874786376, 65: 2.638949155807495, 70: 2.646826696395874, 75: 2.652721107006073, 80: 2.6587307929992674, 85: 2.6643563747406005, 90: 2.6700168371200563, 95: 2.6780772686004637, 99: 2.6878706765174867}, 3: {5: 1.8377168893814086, 10: 2.0408205509185793, 15: 2.13863787651062, 20: 2.2119904041290286, 25: 2.256948947906494, 30: 2.2967950344085692, 35: 2.3314809560775758, 40: 2.3682532787322996, 45: 2.4063676238059997, 50: 2.4435397386550903, 55: 2.4861894488334655, 60: 2.5227307796478273, 65: 2.556278955936432, 70: 2.586689281463623, 75: 2.6087729930877686, 80: 2.6262892723083495, 85: 2.6412578344345095, 90: 2.6540517568588258, 95: 2.667634677886963, 99: 2.6834234595298767}, 4: {5: 1.9252358078956604, 10: 2.0970330715179446, 15: 2.187380313873291, 20: 2.246551322937012, 25: 2.2946306467056274, 30: 2.329634761810303, 35: 2.371750259399414, 40: 2.40594687461853, 45: 2.4444894075393675, 50: 2.4871773719787598, 55: 2.5250325918197634, 60: 2.5589614868164063, 65: 2.586638736724854, 70: 2.6078299999237062, 75: 2.625823974609375, 80: 2.638818645477295, 85: 2.6510476589202883, 90: 2.66172194480896, 95: 2.6733288764953613, 99: 2.685797915458679}, 5: {5: 1.943874979019165, 10: 2.1612815856933594, 15: 2.266198015213013, 20: 2.3341619968414307, 25: 2.3806450366973877, 30: 2.4192399978637695, 35: 2.4568277835845946, 40: 2.4886952877044677, 45: 2.5139502048492433, 50: 2.5360212326049805, 55: 2.5599576950073244, 60: 2.581161451339722, 65: 2.6007281303405763, 70: 2.6170677661895754, 75: 2.6306514739990234, 80: 2.6419496536254883, 85: 2.651454734802246, 90: 2.661288356781006, 95: 2.6730101108551025, 99: 2.6850211906433104}, 6: {5: 0.2819471135735512, 10: 0.5058989822864532, 15: 0.6752008497714996, 20: 0.960327684879303, 25: 1.3793651461601257, 30: 1.675190031528473, 35: 1.8846439123153687, 40: 2.0372345447540283, 45: 2.139349341392517, 50: 2.2228822708129883, 55: 2.28964626789093, 60: 2.3434484004974365, 65: 2.4019185304641724, 70: 2.455880284309387, 75: 2.510001838207245, 80: 2.559812307357788, 85: 2.6031156182289124, 90: 2.6335586309432983, 95: 2.657118797302246, 99: 2.6806323766708373}, 7: {5: 0.5282319933176041, 10: 0.6864366590976716, 15: 0.966709554195404, 20: 1.3708524227142336, 25: 1.6716769933700562, 30: 1.867395257949829, 35: 2.0097468614578244, 40: 2.1105203151702883, 45: 2.1868439674377442, 50: 2.253596544265747, 55: 2.3096351623535156, 60: 2.3542639732360837, 65: 2.3983959317207337, 70: 2.44179425239563, 75: 2.485235035419464, 80: 2.526264715194702, 85: 2.5703901171684262, 90: 2.6214015007019045, 95: 2.6560380458831787, 99: 2.6808297777175905}, 8: {5: 0.02083910163491965, 10: 0.3068426668643952, 15: 0.8975286543369292, 20: 1.315480661392212, 25: 1.6043683290481567, 30: 1.8607874631881713, 35: 2.029924154281616, 40: 2.167367458343506, 45: 2.2649277687072753, 50: 2.333171844482422, 55: 2.3848376274108887, 60: 2.429859161376953, 65: 2.4669673442840576, 70: 2.5048004150390626, 75: 2.535951018333435, 80: 2.570956087112427, 85: 2.608888101577759, 90: 2.6379926204681396, 95: 2.6609750032424926, 99: 2.6814684200286867}, 9: {5: 1.8272866010665894, 10: 2.0309409379959105, 15: 2.146775245666504, 20: 2.2186398983001707, 25: 2.2706140875816345, 30: 2.314206838607788, 35: 2.3553284287452696, 40: 2.395247507095337, 45: 2.4335177421569822, 50: 2.470583438873291, 55: 2.5131633043289185, 60: 2.545176076889038, 65: 2.576409196853638, 70: 2.6037368059158323, 75: 2.623080313205719, 80: 2.6390114784240724, 85: 2.6517002105712892, 90: 2.6618347644805906, 95: 2.6737817764282226, 99: 2.686875219345093}, 10: {5: 1.9659386157989502, 10: 2.1264392852783205, 15: 2.21094331741333, 20: 2.2760358810424806, 25: 2.320758104324341, 30: 2.3618499279022216, 35: 2.401571035385132, 40: 2.4381027221679688, 45: 2.470730113983154, 50: 2.5078964233398438, 55: 2.5359577178955077, 60: 2.563608169555664, 65: 2.588165616989136, 70: 2.606923151016235, 75: 2.6234631538391113, 80: 2.638383150100708, 85: 2.649264097213745, 90: 2.659928226470947, 95: 2.6716168403625487, 99: 2.6849864768981933}, 11: {5: 1.9246153593063355, 10: 2.0922578096389772, 15: 2.178054630756378, 20: 2.2469607830047607, 25: 2.2957547307014465, 30: 2.3304651975631714, 35: 2.3648979663848877, 40: 2.402110242843628, 45: 2.4381957769393923, 50: 2.4739038944244385, 55: 2.512332808971405, 60: 2.5472160816192626, 65: 2.5782777667045593, 70: 2.6001659631729126, 75: 2.6195346117019653, 80: 2.6342700958251952, 85: 2.6466667532920836, 90: 2.656973695755005, 95: 2.66965891122818, 99: 2.684490158557892}, 12: {5: 1.9674898386001587, 10: 2.1301509857177736, 15: 2.214477491378784, 20: 2.2786465167999266, 25: 2.3253331184387207, 30: 2.367804002761841, 35: 2.4093472003936767, 40: 2.4476913928985597, 45: 2.487336015701294, 50: 2.520127296447754, 55: 2.5478708744049072, 60: 2.5751532077789308, 65: 2.595901870727539, 70: 2.6135385513305662, 75: 2.627126693725586, 80: 2.638811779022217, 85: 2.648935842514038, 90: 2.659759759902954, 95: 2.6715378761291504, 99: 2.6847093009948733}, 13: {5: 1.9021955728530884, 10: 2.082094669342041, 15: 2.180007076263428, 20: 2.243494415283203, 25: 2.299072742462158, 30: 2.3417056083679197, 35: 2.3846180915832518, 40: 2.4251920700073244, 45: 2.4639820098876952, 50: 2.5060083866119385, 55: 2.5412569522857664, 60: 2.5726976871490477, 65: 2.5960153579711913, 70: 2.6140268325805662, 75: 2.6286115646362305, 80: 2.6401853561401367, 85: 2.6511096477508547, 90: 2.661820983886719, 95: 2.673285722732544, 99: 2.685934658050537}, 14: {5: 1.9117946386337281, 10: 2.0965224742889403, 15: 2.1842168807983398, 20: 2.2441794872283936, 25: 2.295366048812866, 30: 2.332827568054199, 35: 2.3698036670684814, 40: 2.4091558933258055, 45: 2.444316864013672, 50: 2.4814538955688477, 55: 2.521476745605469, 60: 2.5567267417907713, 65: 2.5847618103027346, 70: 2.607064723968506, 75: 2.6260690689086914, 80: 2.640302133560181, 85: 2.651486301422119, 90: 2.6616422653198244, 95: 2.672612953186035, 99: 2.684949960708618}}
        self.all_help_info = all_help_info

    def determine_ask_for_help(self, metric, risk, act, dist):
        if metric == "msp":
            need_help = torch.log(dist.probs.max()) < np.log(self.max_probability_thresholds[risk])
        elif metric == "sampled_p":
            # need_help = dist.log_prob(act) < np.log(self.sampled_probability_thresholds[risk])
            need_help = torch.log(dist.log_prob(act)) < np.log(self.probability_thresholds_by_action[act.item()][risk])
        elif metric == "ml":
            need_help = dist.logits.max() < self.max_logit_thresholds[risk]
        elif metric == "sampled_l":
            # need_help = dist.logits.squeeze()[act] < self.sampled_logit_thresholds[risk]
            need_help = torch.log(dist.log_prob(act)) < np.log(self.logit_thresholds_by_action[act.item()][risk])
        elif metric == "ent":
            # need_help = dist.entropy() > self.entropy_thresholds[100 - risk]
            need_help = torch.log(dist.log_prob(act)) < np.log(self.entropy_thresholds_by_action[act.item()][risk])
        help_info = {}
        sorted_probs, sorted_indices = torch.sort(dist.probs, descending = True)
        sorted_probs = sorted_probs.squeeze()
        sorted_indices = sorted_indices.squeeze()
        sorted_logits = dist.logits.squeeze()[sorted_indices]
        # action_info is a list of tuples (action name, probability, logit)
        if self.reduced_action_space:
            mapping = ACTION_MAPPING
        else:
            mapping = ORIGINAL_ACTION_MAPPING
        action_info = [(mapping[act.item()], dist.probs.squeeze()[act.item()].item(), dist.logits.squeeze()[act.item()].item())]
        for idx in sorted_indices:
            if idx.item() != act.item():
                action_info.append((mapping[idx.item()], sorted_probs[idx.item()].item(), sorted_logits[idx.item()].item()))
        help_info["action_info"] = action_info
        help_info["entropy"] = dist.entropy().item()
        help_info["need_help"] = need_help.item() if isinstance(need_help, torch.Tensor) else need_help
        self.all_help_info.append(help_info)
        return need_help, help_info
    
    def predict(self, obs, hidden_state, done, ood_metric = None, risk = None, select_mode = "sample"):
        assert ood_metric in [None, "msp", "ml", "sampled_p", "sampled_l", "ent"], "Check ood metric"
        assert select_mode in ["sample", "max"], "Check select mode"
        if ood_metric is not None:
            assert risk is not None, "Must provide risk for ood metric"
        if isinstance(done, list):
            done = torch.tensor(done).float()
        with torch.no_grad():
            obs = torch.FloatTensor(obs).to(device=self.device)
            hidden_state = torch.FloatTensor(hidden_state).to(device=self.device)
            mask = torch.FloatTensor(1 - done).to(device=self.device)
            dist, value, hidden_state = self.policy(obs, hidden_state, mask)
            if select_mode == "sample":
                act = dist.sample()
            else:
                act = torch.argmax(dist.probs).unsqueeze(0)
            log_prob_act = dist.log_prob(act)
            if self.store_percentiles:
                action_probs = dist.probs.gather(1, act.unsqueeze(-1)).squeeze(-1).cpu().numpy()
                action_logits = dist.logits.gather(1, act.unsqueeze(-1)).squeeze(-1).cpu().numpy()
                entropies = dist.entropy().cpu().numpy()
                self.all_max_probs.extend(dist.probs.max(dim = -1)[0].cpu().numpy())
                self.all_sampled_probs.extend(action_probs)
                self.all_max_logits.extend(dist.logits.max(dim = -1)[0].cpu().numpy())
                self.all_sampled_logits.extend(action_logits)
                self.all_entropies.extend(entropies)
                for i in range(act.shape[0]):
                    self.probs_by_action[act.cpu().numpy()[i]].append(action_probs[i])
                    self.logits_by_action[act.cpu().numpy()[i]].append(action_logits[i])
                    self.entropies_by_action[act.cpu().numpy()[i]].append(entropies[i])
        if ood_metric is not None:
           need_help, help_info = self.determine_ask_for_help(ood_metric, risk, act, dist)
           if need_help:
               self.num_requests += 1
        else:
            help_info = None
        return act.cpu().numpy(), log_prob_act.cpu().numpy(), value.cpu().numpy(), hidden_state.cpu().numpy(), help_info

    def predict_w_value_saliency(self, obs, hidden_state, done):
        obs = torch.FloatTensor(obs).to(device=self.device)
        obs.requires_grad_()
        obs.retain_grad()
        hidden_state = torch.FloatTensor(hidden_state).to(device=self.device)
        mask = torch.FloatTensor(1-done).to(device=self.device)
        dist, value, hidden_state = self.policy(obs, hidden_state, mask)
        value.backward(retain_graph=True)
        act = dist.sample()
        log_prob_act = dist.log_prob(act)

        return act.detach().cpu().numpy(), log_prob_act.detach().cpu().numpy(), value.detach().cpu().numpy(), hidden_state.detach().cpu().numpy(), obs.grad.data.detach().cpu().numpy()

    def optimize(self):
        pi_loss_list, value_loss_list, entropy_loss_list = [], [], []
        batch_size = self.n_steps * self.n_envs // self.mini_batch_per_epoch
        if batch_size < self.mini_batch_size:
            self.mini_batch_size = batch_size
        grad_accumulation_steps = batch_size / self.mini_batch_size
        grad_accumulation_cnt = 1

        self.policy.train()
        for e in range(self.epoch):
            recurrent = self.policy.is_recurrent()
            generator = self.storage.fetch_train_generator(mini_batch_size=self.mini_batch_size,
                                                           recurrent=recurrent)
            for sample in generator:
                obs_batch, hidden_state_batch, act_batch, done_batch, \
                    old_log_prob_act_batch, old_value_batch, return_batch, adv_batch = sample
                mask_batch = (1-done_batch)
                dist_batch, value_batch, _ = self.policy(obs_batch, hidden_state_batch, mask_batch)

                # Clipped Surrogate Objective
                log_prob_act_batch = dist_batch.log_prob(act_batch)
                ratio = torch.exp(log_prob_act_batch - old_log_prob_act_batch)
                surr1 = ratio * adv_batch
                surr2 = torch.clamp(ratio, 1.0 - self.eps_clip, 1.0 + self.eps_clip) * adv_batch
                pi_loss = -torch.min(surr1, surr2).mean()

                # Clipped Bellman-Error
                clipped_value_batch = old_value_batch + (value_batch - old_value_batch).clamp(-self.eps_clip, self.eps_clip)
                v_surr1 = (value_batch - return_batch).pow(2)
                v_surr2 = (clipped_value_batch - return_batch).pow(2)
                value_loss = 0.5 * torch.max(v_surr1, v_surr2).mean()

                # Policy Entropy
                entropy_loss = dist_batch.entropy().mean()
                loss = pi_loss + self.value_coef * value_loss - self.entropy_coef * entropy_loss
                loss.backward()

                # Let model to handle the large batch-size with small gpu-memory
                if grad_accumulation_cnt % grad_accumulation_steps == 0:
                    torch.nn.utils.clip_grad_norm_(self.policy.parameters(), self.grad_clip_norm)
                    self.optimizer.step()
                    self.optimizer.zero_grad()
                grad_accumulation_cnt += 1
                pi_loss_list.append(-pi_loss.item())
                value_loss_list.append(-value_loss.item())
                entropy_loss_list.append(entropy_loss.item())

        summary = {'Loss/pi': np.mean(pi_loss_list),
                   'Loss/v': np.mean(value_loss_list),
                   'Loss/entropy': np.mean(entropy_loss_list)}
        return summary

    def train(self, num_timesteps, reduced_action_space):
        save_every = num_timesteps // self.num_checkpoints
        checkpoint_cnt = 0
        save_timestep_index = 0
        obs = self.env.reset()
        hidden_state = np.zeros((self.n_envs, self.storage.hidden_state_size))
        done = np.zeros(self.n_envs)

        if self.env_valid is not None:
            obs_v = self.env_valid.reset()
            hidden_state_v = np.zeros((self.n_envs, self.storage.hidden_state_size))
            done_v = np.zeros(self.n_envs)

        while self.t < num_timesteps:
            # Run Policy
            self.policy.eval()
            for _ in range(self.n_steps):
                act, log_prob_act, value, next_hidden_state, help_info = self.predict(obs, hidden_state, done, ood_metric = "msp")
                if reduced_action_space:
                    act = ACTION_TRANSLATION[act]
                    assert act.shape == log_prob_act.shape, "Messed up converting actions"
                next_obs, rew, done, info = self.env.step(act)
                self.storage.store(obs, hidden_state, act, rew, done, info, log_prob_act, value, help_info)
                obs = next_obs
                hidden_state = next_hidden_state
            value_batch = self.storage.value_batch[:self.n_steps]
            _, _, last_val, hidden_state, help_info = self.predict(obs, hidden_state, done, ood_metric = "msp")
            self.storage.store_last(obs, hidden_state, last_val, help_info)
            self.storage.compute_estimates(self.gamma, self.lmbda, self.use_gae, self.normalize_adv)

            #valid
            if self.env_valid is not None:
                for _ in range(self.n_steps):
                    act_v, log_prob_act_v, value_v, next_hidden_state_v, help_info = self.predict(obs_v, hidden_state_v, done_v, ood_metric = "msp")
                    if reduced_action_space:
                        act = ACTION_TRANSLATION[act]
                        assert act.shape == log_prob_act.shape, "Messed up converting actions (val)"
                    next_obs_v, rew_v, done_v, info_v = self.env_valid.step(act)
                    self.storage_valid.store(obs_v, hidden_state_v, act_v,
                                             rew_v, done_v, info_v,
                                             log_prob_act_v, value_v, help_info)
                    obs_v = next_obs_v
                    hidden_state_v = next_hidden_state_v
                _, _, last_val_v, hidden_state_v, help_info = self.predict(obs_v, hidden_state_v, done_v, ood_metric = "msp")
                self.storage_valid.store_last(obs_v, hidden_state_v, last_val_v, help_info)
                self.storage_valid.compute_estimates(self.gamma, self.lmbda, self.use_gae, self.normalize_adv)

            # Optimize policy & valueq
            summary = self.optimize()
            # Log the training-procedure
            self.t += self.n_steps * self.n_envs
            rew_batch, done_batch = self.storage.fetch_log_data()
            if self.storage_valid is not None:
                rew_batch_v, done_batch_v = self.storage_valid.fetch_log_data()
            else:
                rew_batch_v = done_batch_v = None
            self.logger.feed(rew_batch, done_batch, rew_batch_v, done_batch_v)
            self.logger.dump()
            self.optimizer = adjust_lr(self.optimizer, self.learning_rate, self.t, num_timesteps)
            # Save the model
            if self.use_save_intervals:
                if self.t > ((checkpoint_cnt+1) * save_every):
                    print("Saving model.")
                    torch.save({'model_state_dict': self.policy.state_dict(),
                                'optimizer_state_dict': self.optimizer.state_dict()},
                                self.logger.logdir + '/model_' + str(self.t) + '.pth')
                    checkpoint_cnt += 1
            else:
                try:
                    if self.t + 1 >= self.save_timesteps[save_timestep_index]:
                        print("Saving model at timestep", self.t + 1)
                        torch.save({'model_state_dict': self.policy.state_dict(),
                                    'optimizer_state_dict': self.optimizer.state_dict()},
                                    self.logger.logdir + '/model_' + str(self.t) + '.pth')
                        save_timestep_index += 1
                except IndexError:  # no more timesteps needed to be saved
                    pass
        self.env.close()
        if self.env_valid is not None:
            self.env_valid.close()
        # if self.store_percentiles:
        #     with open(self.logger.logdir + "/all_probs.pkl", "wb") as f:
        #         pickle.dump(self.all_probs, f)
        #     with open(self.logger.logdir + "/all_logits.pkl", "wb") as f:
        #         pickle.dump(self.all_logits, f)
        #     with open(self.logger.logdir + "/probs_by_action.pkl", "wb") as f:
        #         pickle.dump(self.probs_by_action, f)
        #     with open(self.logger.logdir + "/logits_by_action.pkl", "wb") as f:
        #         pickle.dump(self.logits_by_action, f)

